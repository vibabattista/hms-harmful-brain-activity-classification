{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":8056602,"sourceType":"datasetVersion","datasetId":4751858},{"sourceId":8057954,"sourceType":"datasetVersion","datasetId":4752816},{"sourceId":8065225,"sourceType":"datasetVersion","datasetId":4758149},{"sourceId":8066192,"sourceType":"datasetVersion","datasetId":4758876},{"sourceId":8066496,"sourceType":"datasetVersion","datasetId":4759082},{"sourceId":8067557,"sourceType":"datasetVersion","datasetId":4759857},{"sourceId":170850593,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport jax\nimport jax.numpy as jnp\nimport jax.random as jr\nimport jax.nn as jnn\nfrom jax import ops\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time as time\n\nfrom sklearn.preprocessing import LabelEncoder\n# from tslearn.datasets import UCR_UEA_datasets\n# from tslearn.preprocessing import TimeSeriesScalerMeanVariance\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nimport pywt\n\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm\n# import os\n# import sys\nfrom joblib import dump, load\n\nimport utility\n#sys.path.append('/kaggle/usr/lib/utility')\nimport sigkerax\nfrom sigkerax.sigkernel import SigKernel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T23:06:02.867725Z","iopub.execute_input":"2024-04-08T23:06:02.868422Z","iopub.status.idle":"2024-04-08T23:06:02.879379Z","shell.execute_reply.started":"2024-04-08T23:06:02.868350Z","shell.execute_reply":"2024-04-08T23:06:02.877617Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Submission notebook: no training\nLoading models and applying to a generic test dataframe","metadata":{}},{"cell_type":"code","source":"PATH_TRAIN = '/kaggle/input/hms-harmful-brain-activity-classification/train.csv'\nEEG_PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/'\nFEATS = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\ndf = pd.read_csv(PATH_TRAIN)\nTARGETS = df.columns[-6:]\ndf_unique = df.drop_duplicates(subset=['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote'], keep='first')\ndf_unique[TARGETS] = df_unique[TARGETS].astype('float64')\ny = df_unique[TARGETS].agg('sum', axis=1)\ndf_unique.loc[:,'sum_votes']=y\n# strong samples\ndf_unique = df_unique.loc[df_unique['sum_votes']>10]\n#unanimous samples\n# df_unique['max_category_votes'] = df_unique[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].max(axis=1)\n# df_unique = df_unique[df_unique['max_category_votes'] == df_unique['sum_votes']]\n# df_unique.drop(columns=['max_category_votes'], inplace=True)\n#df_unique.loc[:, TARGETS] = v.astype('float64')\nlen(df_unique)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T22:58:57.118447Z","iopub.execute_input":"2024-04-08T22:58:57.119808Z","iopub.status.idle":"2024-04-08T22:58:57.366688Z","shell.execute_reply.started":"2024-04-08T22:58:57.119737Z","shell.execute_reply":"2024-04-08T22:58:57.365445Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/774425918.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_unique[TARGETS] = df_unique[TARGETS].astype('float64')\n/tmp/ipykernel_33/774425918.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_unique.loc[:,'sum_votes']=y\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"6233"},"metadata":{}}]},{"cell_type":"code","source":"PATH_TEST = '/kaggle/input/hms-harmful-brain-activity-classification/test.csv'\nEEG_PATH_TEST = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\nFEATS = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\ndf_test = pd.read_csv(PATH_TEST)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T21:56:45.972445Z","iopub.execute_input":"2024-04-08T21:56:45.973633Z","iopub.status.idle":"2024-04-08T21:56:45.985173Z","shell.execute_reply.started":"2024-04-08T21:56:45.973589Z","shell.execute_reply":"2024-04-08T21:56:45.983945Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\ndef denoise(x, wavelet='haar', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    ret=pywt.waverec(coeff, wavelet, mode='per')\n\n    return ret\ndef montage(eeg_data, electrodes=FEATS):\n    \"\"\"\n    Apply bipolar montaging to EEG data.\n    \n    Parameters:\n    - eeg_data: NumPy array with shape (timepoints, channels), where channels correspond to electrodes.\n    - electrodes: List of electrode names in the same order as the eeg_data channels.\n    \n    Returns:\n    - montaged_data: NumPy array after applying bipolar montaging.\n    \"\"\"\n    # Define pairs for bipolar montage based on electrode positions\n    # This is a simplified example; pairs should be chosen based on electrode locations and analysis needs\n    pairs = [('Fp1', 'T3'), ('T3', 'O1'), ('Fp1', 'C3'), ('C3', 'O1'),\n             ('Fp2', 'C4'), ('C4', 'O2'), ('Fp2', 'T4'), ('T4', 'O2')]\n    \n    montaged_data = []\n    for pair in pairs:\n        idx1 = electrodes.index(pair[0])\n        idx2 = electrodes.index(pair[1])\n        # Compute the difference between the pairs\n        montaged_data.append(eeg_data[:, idx1] - eeg_data[:, idx2])\n    \n    # Stack the montaged data to form a new array\n    montaged_data = np.stack(montaged_data, axis=-1)\n    \n    return montaged_data\ndef ft(eeg_data):\n    # Apply Fast Fourier Transform (FFT) to each channel\n    fft_results = np.fft.rfft(eeg_data, axis=0)\n    \n    # Compute magnitude spectrum (amplitude)\n    magnitude_spectrum = np.abs(fft_results)\n    \n    # Optionally, compute the power spectrum or log power spectrum for analysis\n    power_spectrum = np.square(magnitude_spectrum)\n    log_power_spectrum = np.log(power_spectrum + 1e-10)  # Adding epsilon to avoid log(0)\n    \n    return log_power_spectrum\n\ndef fft_filter(signal, fs):\n    \"\"\"\n    Filters the EEG signal to retain important brain wave frequencies\n    and reduces the size by a factor of 8.\n    \n    Parameters:\n    - signal: The time-domain EEG signal (1D numpy array).\n    - fs: Sampling frequency of the signal.\n    \n    Returns:\n    - reduced_signal: The time-domain signal after filtering and size reduction.\n    \"\"\"\n    # Perform FFT\n    fft_result = np.fft.fft(signal)\n    freq = np.fft.fftfreq(len(signal), d=1/fs)\n    \n    # Define brain wave frequency ranges\n    delta = (0.5, 4)\n    theta = (4, 8)\n    alpha = (8, 12)\n    beta = (12, 30)\n    \n    # Create a mask to retain frequencies within the defined brain wave ranges\n    mask = ((np.abs(freq) >= delta[0]) & (np.abs(freq) <= delta[1])) | \\\n           ((np.abs(freq) >= theta[0]) & (np.abs(freq) <= theta[1])) | \\\n           ((np.abs(freq) >= alpha[0]) & (np.abs(freq) <= alpha[1])) | \\\n           ((np.abs(freq) >= beta[0]) & (np.abs(freq) <= beta[1]))\n    \n    # Apply mask and zero out other frequencies\n    fft_result_filtered = np.zeros_like(fft_result)\n    fft_result_filtered[mask] = fft_result[mask]\n    \n    # Optionally, reduce the size of the filtered FFT result by a factor of 8\n    # This simplistic approach keeps every 8th frequency component\n    reduction_factor = 2\n    reduced_fft_result_filtered = fft_result_filtered[::reduction_factor]\n    \n    # Perform Inverse FFT to get the filtered, reduced signal back in time domain\n    reduced_signal = np.fft.ifft(reduced_fft_result_filtered).real\n    \n    return reduced_signal[::4]\n\ndef load_data_batch(batch_size, batch_num, df= df_unique):\n    test_mode = df.equals(df_test)\n    EEG_PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/' if test_mode else '/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/'\n    start_index = batch_num * batch_size\n    end_index = start_index + batch_size\n    batch_df = df.iloc[start_index:end_index]\n    data = []\n\n    for row in batch_df.itertuples():\n        eeg_id = getattr(row, 'eeg_id')\n        offset = int(getattr(row, 'eeg_label_offset_seconds') * 200) if not test_mode else 0\n        eeg = pq.read_table(f\"{EEG_PATH}{eeg_id}.parquet\").to_pandas().iloc[offset + 4000:offset + 6000]\n        eeg = eeg.loc[:, eeg.columns.isin(FEATS)].ffill().bfill().values\n        #eeg = montage(eeg)\n        #eeg = denoise(eeg)\n        eeg = fft_filter(eeg,200)\n        #eeg = montage(eeg)\n        \n        max_val = np.abs(eeg).max(axis=0, keepdims=True)\n        max_val[max_val == 0] = 1  # Replace 0s with 1s to avoid division by zero\n        eeg /= max_val\n        data.append(eeg)\n\n    # Convert the list of numpy arrays to a single JAX array\n    return jnp.array(data)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T22:58:44.902405Z","iopub.execute_input":"2024-04-08T22:58:44.903438Z","iopub.status.idle":"2024-04-08T22:58:44.931071Z","shell.execute_reply.started":"2024-04-08T22:58:44.903392Z","shell.execute_reply":"2024-04-08T22:58:44.929741Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def construct_kernel_matrix(df1, df2, sigma, signature_kernel, num_batches = 10):\n    n = df1.shape[0]\n    m = df2.shape[0]\n    global_kernel_matrix = jnp.zeros((n,m))\n    \n    batch_size = math.ceil(n / num_batches)\n    # initialize signature PDE kernel\n#     signature_kernel = SigKernel(refinement_factor=1, static_kernel_kind=\"rbf\", scales = jnp.array([sigma]), add_time=True)\n    for i in range(num_batches):\n        # load batch i\n        t1 = time.time()\n        X_batch = load_data_batch(batch_size, i, df=df1)\n        #X_batch = X_batch[:,::8,:]\n        t2 = time.time()\n        print(f\"load one batch time: {t2-t1}\")\n        for j in tqdm(range(i, num_batches)):  # Use range(i, num_batches) to avoid redundant calculations\n            # Load batch j\n            Y_batch = load_data_batch(batch_size, j, df=df2)\n            # slice and scale\n            #Y_batch = Y_batch[:,::8,:]\n#             X_batch *= 0.001\n#             Y_batch *= 0.001\n            t1 = time.time()\n            # Compute the kernel matrix between these two batches\n            local_kernel_matrix = signature_kernel.kernel_matrix(X_batch, Y_batch)[...,0]\n            t2 = time.time()\n            print(f\"local kernel time: {t2-t1}\")\n            #Insert the local kernel matrix into the global matrix\n            start_i, end_i = i * batch_size, (i + 1) * batch_size\n            start_j, end_j = j * batch_size, (j + 1) * batch_size\n            t1 = time.time()\n            global_kernel_matrix = global_kernel_matrix.at[start_i:end_i, start_j:end_j].set(local_kernel_matrix)\n            t2 = time.time()\n            #print(f\"assign to global kernel time: {t2-t1}\")\n            # For the non-diagonal blocks, where i != j, fill the symmetric position in the matrix\n            if i != j:\n                global_kernel_matrix = global_kernel_matrix.at[start_j:end_j, start_i:end_i].set(local_kernel_matrix.T)\n    return jnp.array(global_kernel_matrix)\n\ndef test_matrix(df1, df2, sigma, signature_kernel, batch_size=10):\n    n = df1.shape[0]\n    m = df2.shape[0]\n    global_kernel_matrix = jnp.zeros((n, m))\n    \n    # Calculate the number of batches for each dataframe\n    num_batches_df1 = math.ceil(n / batch_size)\n    num_batches_df2 = math.ceil(m / batch_size)\n    \n    for i in tqdm(range(num_batches_df1), desc=\"Computing kernel matrix\", leave=False):\n        # Dynamically compute start and end indices for df1 batches\n        start_i = i * batch_size\n        end_i = min(start_i + batch_size, n)\n        X_batch = load_data_batch(end_i - start_i, i, df=df1)\n\n        for j in range(num_batches_df2):\n            # Dynamically compute start and end indices for df2 batches\n            start_j = j * batch_size\n            end_j = min(start_j + batch_size, m)\n            Y_batch = load_data_batch(end_j - start_j, j, df=df2)\n            \n            # Compute the kernel matrix between X_batch and Y_batch\n            local_kernel_matrix = signature_kernel.kernel_matrix(X_batch, Y_batch)[..., 0]\n            \n            # Insert the local kernel matrix into the appropriate slice of the global matrix\n            global_kernel_matrix = global_kernel_matrix.at[start_i:end_i, start_j:end_j].set(local_kernel_matrix)\n    del(X_batch)\n    del(Y_batch)\n    return global_kernel_matrix","metadata":{"execution":{"iopub.status.busy":"2024-04-08T22:54:52.388959Z","iopub.execute_input":"2024-04-08T22:54:52.389735Z","iopub.status.idle":"2024-04-08T22:54:52.408555Z","shell.execute_reply.started":"2024-04-08T22:54:52.389695Z","shell.execute_reply":"2024-04-08T22:54:52.407575Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def kld(p, q):\n    \"\"\"\n    Calculate the Kullback-Leibler Divergence between two probability distributions.\n    \n    Parameters:\n    - p: The true probability distribution (as a NumPy array).\n    - q: The predicted probability distribution (as a NumPy array).\n    \n    Returns:\n    - The KL Divergence value.\n    \"\"\"\n    # Ensure the distributions sum to 1 (if they don't already)\n    p_normalized = p / np.sum(p)\n    q_normalized = q / np.sum(q)\n    \n    # Only consider non-zero elements\n    nonzero_indices = (p_normalized > 0) & (q_normalized > 0)\n    \n    return np.sum(p_normalized[nonzero_indices] * np.log(p_normalized[nonzero_indices] / q_normalized[nonzero_indices]))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T22:54:54.720521Z","iopub.execute_input":"2024-04-08T22:54:54.721346Z","iopub.status.idle":"2024-04-08T22:54:54.729377Z","shell.execute_reply.started":"2024-04-08T22:54:54.721300Z","shell.execute_reply":"2024-04-08T22:54:54.728161Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_unique = df_unique.iloc[:4000]\nmodel_path = '/kaggle/input/final-fft-model/kernel_ridge_model_fft_filter_final_model.joblib'\nkrr = load(model_path)\nsigma = 0.01\n\nsignature_kernel = SigKernel(refinement_factor=2, static_kernel_kind=\"linear\", scales = jnp.array([sigma]), add_time=True)\n\nK_test = test_matrix(df_test, df_unique, sigma, signature_kernel, 500)\ntest_predictions = krr.predict(K_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T22:59:02.723512Z","iopub.execute_input":"2024-04-08T22:59:02.724341Z","iopub.status.idle":"2024-04-08T23:02:01.215299Z","shell.execute_reply.started":"2024-04-08T22:59:02.724293Z","shell.execute_reply":"2024-04-08T23:02:01.213129Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"                                                                       \r","output_type":"stream"}]},{"cell_type":"code","source":"scaled_predictions = (jnn.relu(test_predictions).T/jnn.relu(test_predictions).sum(axis = 1)).T","metadata":{"execution":{"iopub.status.busy":"2024-04-08T23:06:08.095218Z","iopub.execute_input":"2024-04-08T23:06:08.096051Z","iopub.status.idle":"2024-04-08T23:06:08.207111Z","shell.execute_reply.started":"2024-04-08T23:06:08.096013Z","shell.execute_reply":"2024-04-08T23:06:08.206126Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'eeg_id': df_test.eeg_id.values})\nlabels=['seizure_vote','lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']\nsubmission[labels] = scaled_predictions\nsubmission.to_csv(\"submission.csv\",index=None)\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-08T21:58:49.433356Z","iopub.execute_input":"2024-04-08T21:58:49.433690Z","iopub.status.idle":"2024-04-08T21:58:49.459593Z","shell.execute_reply.started":"2024-04-08T21:58:49.433662Z","shell.execute_reply":"2024-04-08T21:58:49.458598Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n0  3911565283      0.051843  0.187102  0.121749   0.083182   0.087862   \n\n   other_vote  \n0    0.468262  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eeg_id</th>\n      <th>seizure_vote</th>\n      <th>lpd_vote</th>\n      <th>gpd_vote</th>\n      <th>lrda_vote</th>\n      <th>grda_vote</th>\n      <th>other_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3911565283</td>\n      <td>0.051843</td>\n      <td>0.187102</td>\n      <td>0.121749</td>\n      <td>0.083182</td>\n      <td>0.087862</td>\n      <td>0.468262</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}